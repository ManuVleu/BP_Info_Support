{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Interface with Gradio for QG & QA\n",
    "T5 Answer Agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ManuV\\AppData\\Local\\miniconda3\\envs\\quiz_generator\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline, BartForConditionalGeneration, AutoTokenizer\n",
    "import Levenshtein\n",
    "import os\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "from utils import Chapter, File\n",
    "\n",
    "SAVE_TREE_DIR = os.path.join(\"C:\", os.sep, \"Users\", \"ManuV\", \"Documents\", \"Bachelorproef\", \"BP_Info_Support\", \"data\")\n",
    "QG_MODEL_NAME = \"ManuVleuBeu/T5_ag_SQuAD\"\n",
    "QA_MODEL_NAME = \"damapika/roberta-base_mod_squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guidance_framework():\n",
    "    with open(os.path.join(SAVE_TREE_DIR,\"gf_structure.pkl\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "root = get_guidance_framework()\n",
    "    \n",
    "def get_all_files():\n",
    "    chapters = root.get_all_chapters()\n",
    "\n",
    "    all_files = []\n",
    "    for chapter in chapters:\n",
    "        all_files.extend(chapter.files)\n",
    "\n",
    "    return all_files\n",
    "\n",
    "files = get_all_files()\n",
    "\n",
    "def clean_file_dirs():\n",
    "    for file in files:\n",
    "        file_dir = '/'.join(file.dir.split('docs\\\\')[1:])\n",
    "        file.dir = file_dir.replace('\\\\','/')\n",
    "\n",
    "    return files\n",
    "\n",
    "files = clean_file_dirs()\n",
    "\n",
    "def get_contexts_from_file_dir(file_dir):\n",
    "    file = [file for file in files if file.dir == file_dir]\n",
    "    if not len(file) == 0:\n",
    "        file = file[0]\n",
    "        # Sorts text per h-elem by biggest\n",
    "        key_ranking = sorted(file.text.keys(), key=lambda k: len(' '.join(file.text[k])), reverse=True)\n",
    "        return [' '.join(file.text[key]) for key in key_ranking]\n",
    "    else:\n",
    "        raise Exception(\"File directory does not exist!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ManuV\\AppData\\Local\\miniconda3\\envs\\quiz_generator\\lib\\site-packages\\gradio\\inputs.py:219: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "c:\\Users\\ManuV\\AppData\\Local\\miniconda3\\envs\\quiz_generator\\lib\\site-packages\\gradio\\inputs.py:222: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "c:\\Users\\ManuV\\AppData\\Local\\miniconda3\\envs\\quiz_generator\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "files = get_all_files()\n",
    "\n",
    "# Question Generation Model\n",
    "question_generator = pipeline(\"text2text-generation\", model=QG_MODEL_NAME)\n",
    "# question_generator = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qa-qg-hl\")\n",
    "\n",
    "# Answer Generation Model\n",
    "answer_generator = pipeline(\"question-answering\", model=QA_MODEL_NAME)\n",
    "# TODO: Add all chapter contexts or an extra function where user selects chapter->context\n",
    "contexts = [file.dir for file in files]\n",
    "selected_context = []\n",
    "generated_question = []\n",
    "\n",
    "def calculate_similarity(answer1, answer2):\n",
    "    similarity_score = 1 - (Levenshtein.distance(answer1.lower(), answer2.lower()) / max(len(answer1), len(answer2)))\n",
    "    return similarity_score\n",
    "\n",
    "def generate_question(file_dir):\n",
    "    global selected_context\n",
    "    global generated_question\n",
    "    contexts = get_contexts_from_file_dir(file_dir)\n",
    "    selected_context.clear()\n",
    "    generated_question.clear()\n",
    "    for context in contexts:\n",
    "        question = question_generator(context)[0]['generated_text']\n",
    "        question = question.split('?')[0]+'?'# Selects first question\n",
    "        # questions = [question.strip() for question in string.split('?') if question.endswith('?')] instead of first question takes multiple per context\n",
    "        generated_question.append(question)\n",
    "    selected_context = contexts\n",
    "    return '\\n'.join(generated_question)\n",
    "\n",
    "# Interface for QG\n",
    "io1 = gr.Interface(\n",
    "    fn=generate_question,\n",
    "    inputs=[\n",
    "        gr.inputs.Dropdown(choices=contexts, label=\"Select a context\", type=\"value\"),\n",
    "    ],\n",
    "    live=False,\n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Generated Question\"),\n",
    "    ],\n",
    "    title=\"Quiz Generator\",\n",
    "    description=\"Select a context, generate a question, and compare your answer.\",\n",
    "    allow_flagging=\"never\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io1.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ManuV\\AppData\\Local\\miniconda3\\envs\\quiz_generator\\lib\\site-packages\\gradio\\inputs.py:219: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "c:\\Users\\ManuV\\AppData\\Local\\miniconda3\\envs\\quiz_generator\\lib\\site-packages\\gradio\\inputs.py:222: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "c:\\Users\\ManuV\\AppData\\Local\\miniconda3\\envs\\quiz_generator\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\ManuV\\AppData\\Local\\Temp\\ipykernel_16868\\2082326991.py:8: UserWarning: You have unused kwarg parameters in Interface, please remove them: {'interface_id': 'io2'}\n",
      "  io2 = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_answer(question,user_answer):\n",
    "    context = selected_context[generated_question.index(question)]\n",
    "    answer = answer_generator(context=context,question=question)\n",
    "    score=calculate_similarity(user_answer,answer['answer'])\n",
    "    return [user_answer,answer['answer'],score]\n",
    "\n",
    "# Additional interface for answer checking\n",
    "io2 = gr.Interface(\n",
    "    fn=generate_answer,\n",
    "    live=False,\n",
    "    inputs=[gr.inputs.Dropdown(choices=generated_question,label=\"Select a question\",type=\"value\"), gr.outputs.Textbox(label=\"User Answer\")],\n",
    "    outputs=[gr.outputs.Textbox(label=\"User Answer\"),gr.outputs.Textbox(label=\"Generated Answer\"),gr.outputs.Textbox(label=\"Levenshtein Answer score\")],\n",
    "    title=\"Answer Checker\",\n",
    "    description=\"Compare your answer.\",\n",
    "    allow_flagging=\"never\",\n",
    "    interface_id = \"io2\"\n",
    ")\n",
    "\n",
    "io2.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
