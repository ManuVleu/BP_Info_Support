{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers \n",
    "import datasets\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "dataset_name = \"quoref\"\n",
    "model_type=\"electra\"\n",
    "model_name= \"damapika/electra-base-discriminator_squad_mod\"\n",
    "models_dir = \"saved_models/electra-base-discriminator_mod_quoref\"\n",
    "checkpoint = 'electra'\n",
    "max_input_length = 308\n",
    "\n",
    "\n",
    "# ## Training\n",
    "learning_rate = 3e-5\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset quoref (C:/Users/dama_/.cache/huggingface/datasets/quoref/default/0.1.0/82bb58a6b25cd8dbb4625a7ba6a5d0a224af1f4d392ca0de8b9e0c23e78557fe)\n",
      "100%|██████████| 2/2 [00:00<00:00, 30.06it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset=datasets.load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'context', 'title', 'url', 'answers'],\n",
       "        num_rows: 19399\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'context', 'title', 'url', 'answers'],\n",
       "        num_rows: 2418\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate max context length for dataset\n",
    "def calc_max_len(dataset):\n",
    "  context_length_max=len(dataset[0]['context'])\n",
    "  for i in range(len(dataset)):\n",
    "    con_len=len(dataset[i]['context'])\n",
    "    if(con_len<context_length_max):\n",
    "      context_length_max=con_len\n",
    "      print(context_length_max)\n",
    "      print(dataset[i]['context'])\n",
    "  return context_length_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1321\n",
      "In 1919, the Chicago White Sox are considered one of the greatest baseball teams ever assembled; however, the team's stingy owner, Charles Comiskey, gives little inclination to reward his players for a spectacular season.\n",
      "Gamblers \"Sleepy\" Bill Burns and Billy Maharg get wind of the players' discontent, asking shady player Chick Gandil to convince a select group of Sox—including star knuckleball pitcher Eddie Cicotte, who led the majors with a 29–7 win–loss record and an earned run average of 1.82—that they could earn more money by playing badly and throwing the series than they could earn by winning the World Series against the Cincinnati Reds . Cicotte was motivated because Comiskey refused him a promised $10,000 should he win 30 games for the season. Cicotte was nearing the milestone until Comiskey ordered team manager Kid Gleason to bench him for 2 weeks (missing 5 starts) with the excuse that the 35-year-old veteran's arm needed a rest before the series.\n",
      "A number of players, including Gandil, Swede Risberg, and Lefty Williams, go along with the scheme. Shoeless Joe Jackson, an illiterate and the team hitting star is also invited, but is depicted as being not bright and not entirely sure of what is going on. Buck Weaver, meanwhile, insists that he is a winner and wants nothing to do with the fix.\n",
      "1013\n",
      "Jim Madden, a Texas Ranger, is gunned down while investigating the murder of a local rancher.  His younger brother, Larry, vows to track down the suspected killer, another rancher named Joan Stanton.  While looking into the murders, he stumbles on a battle between Stanton, and a group of men working for another rancher, Frank Sanderson. Rescuing Stanton from the altercation, he keeps his identity as a Ranger secret, while attempting to learn the truth of what is going on.  Through talks with Stanton, Madden learns that Sanderson has been setting her up for both the murder of the other rancher, and Jim's death.\n",
      "Convinced by Stanton's story, Madden tells Stanton she must turn herself in, and she agrees. Before they can reach the Rangers, they are captured by Sanderson's men.  Sanderson plans to kill Madden, and take Stanton to Mexico.  With the help of Rangers' cook, Rusty, as well as several of Stanton's men, Madden overcomes Sanderson and his men, and takes a vindicated Stanton back to the Rangers.\n",
      "559\n",
      "Following an establishing shot of the New York City skyline, an elevator in a busy office building opens and happy-go-lucky Sky Ames steps out. In a joyful mood, singing to himself, he takes out a ring, puts it on third finger of his left hand and goes to the door marked \"Eaton, Eiton, Piper & Holland Advertising Agency\". Inside, Miss Wilson, secretary to his best friend, Jeff Holland tells him that Jeff is in a meeting. Showing her the ring, Sky explains that during the first vacation he took without Jeff, he met \"the most wonderful girl in the world\".\n",
      "451\n",
      "The story starts in sequence with 16-year-old Alison Findlay and her two friends playing a seemingly innocent ouija board game. Upon contacting a spirit, who is later revealed to be Alison's dead father (she never knew her actual parents), the girls discover that Alison is in danger. The spirit then possesses one of the girls and warns her not to return home for her 19th birthday. The girl is immediately killed after a bookcase collapses onto her.\n",
      "308\n",
      "Jack Murphy, a hardened, antisocial LAPD detective, frequently escapes the harsh reality that his ex-wife has become a stripper and his career is going nowhere by drinking. His world is turned upside down, however, when he is framed by ex-convict Joan Freeman for putting her in prison earlier in his career.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_max_len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "model = transformers.AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_input_length ,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to CUDA\n",
    "    device = torch.device('cuda')\n",
    "    print('gpu')\n",
    "else:\n",
    "    # If CUDA is not available, fall back to CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/damapika/electra-base-discriminator_mod_quoref into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=models_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdamapika\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\dama_\\OneDrive\\Desktop\\HoGent\\2022_2023\\BP\\BP_Info_Support\\bert\\wandb\\run-20230524_102647-b44add72</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/damapika/huggingface/runs/b44add72' target=\"_blank\">solar-feather-27</a></strong> to <a href='https://wandb.ai/damapika/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/damapika/huggingface' target=\"_blank\">https://wandb.ai/damapika/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/damapika/huggingface/runs/b44add72' target=\"_blank\">https://wandb.ai/damapika/huggingface/runs/b44add72</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 500/3639 [04:16<28:05,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0232, 'learning_rate': 2.5877988458367684e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1000/3639 [08:47<20:18,  2.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6037, 'learning_rate': 2.1755976916735367e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 33%|███▎      | 1213/3639 [10:53<16:17,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5460432767868042, 'eval_runtime': 22.6556, 'eval_samples_per_second': 106.729, 'eval_steps_per_second': 6.709, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1500/3639 [13:06<16:10,  2.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2728, 'learning_rate': 1.763396537510305e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 2000/3639 [17:13<13:25,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0994, 'learning_rate': 1.3511953833470735e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 2426/3639 [21:05<08:28,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5725703239440918, 'eval_runtime': 22.8523, 'eval_samples_per_second': 105.81, 'eval_steps_per_second': 6.651, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 2500/3639 [21:42<09:12,  2.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0568, 'learning_rate': 9.389942291838417e-06, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 3000/3639 [25:56<04:52,  2.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8181, 'learning_rate': 5.267930750206101e-06, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3500/3639 [29:59<01:08,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8029, 'learning_rate': 1.145919208573784e-06, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 3639/3639 [31:35<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.772193431854248, 'eval_runtime': 25.7213, 'eval_samples_per_second': 94.008, 'eval_steps_per_second': 5.91, 'epoch': 3.0}\n",
      "{'train_runtime': 1898.1318, 'train_samples_per_second': 30.66, 'train_steps_per_second': 1.917, 'train_loss': 1.223366385405127, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3639, training_loss=1.223366385405127, metrics={'train_runtime': 1898.1318, 'train_samples_per_second': 30.66, 'train_steps_per_second': 1.917, 'train_loss': 1.223366385405127, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:b44add72) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▂█</td></tr><tr><td>eval/runtime</td><td>▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▄▅▅▇███</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▄▅▅▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▆▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▄▃▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.77219</td></tr><tr><td>eval/runtime</td><td>25.7213</td></tr><tr><td>eval/samples_per_second</td><td>94.008</td></tr><tr><td>eval/steps_per_second</td><td>5.91</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>3639</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8029</td></tr><tr><td>train/total_flos</td><td>9147772860046128.0</td></tr><tr><td>train/train_loss</td><td>1.22337</td></tr><tr><td>train/train_runtime</td><td>1898.1318</td></tr><tr><td>train/train_samples_per_second</td><td>30.66</td></tr><tr><td>train/train_steps_per_second</td><td>1.917</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-feather-27</strong> at: <a href='https://wandb.ai/damapika/huggingface/runs/b44add72' target=\"_blank\">https://wandb.ai/damapika/huggingface/runs/b44add72</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230524_102647-b44add72\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:b44add72). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\dama_\\OneDrive\\Desktop\\HoGent\\2022_2023\\BP\\BP_Info_Support\\bert\\wandb\\run-20230524_123752-ftdaa38f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/damapika/BP_Info_Support/runs/ftdaa38f' target=\"_blank\">flowing-music-2</a></strong> to <a href='https://wandb.ai/damapika/BP_Info_Support' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/damapika/BP_Info_Support' target=\"_blank\">https://wandb.ai/damapika/BP_Info_Support</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/damapika/BP_Info_Support/runs/ftdaa38f' target=\"_blank\">https://wandb.ai/damapika/BP_Info_Support/runs/ftdaa38f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/damapika/BP_Info_Support/runs/ftdaa38f?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1619a3af690>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "To https://huggingface.co/damapika/electra-base-discriminator_mod_quoref\n",
      "   17999ff..2abe38d  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
