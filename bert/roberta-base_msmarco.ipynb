{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "import datasets\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data[index]\n",
    "        return {\n",
    "            'id': row['id'],\n",
    "            'question': row['question'],\n",
    "            'answer': row['answer'],\n",
    "            'context': row['context'],\n",
    "            'answer_start': row['answer_start'],\n",
    "            'answer_end': row['answer_end']\n",
    "        }\n",
    "\n",
    "    def get(self, index):\n",
    "        return self.__getitem__(index)\n",
    "\n",
    "    def set(self, index, id=None, question=None, answer=None, context=None, answer_start=None, answer_end=None):\n",
    "        if id is not None:\n",
    "            self.data[index]['id'] = id\n",
    "        if question is not None:\n",
    "            self.data[index]['question'] = question\n",
    "        if answer is not None:\n",
    "            self.data[index]['answer'] = answer\n",
    "        if context is not None:\n",
    "            self.data[index]['context'] = context\n",
    "        if answer_start is not None:\n",
    "            self.data[index]['answer_start'] = answer_start\n",
    "        if answer_end is not None:\n",
    "            self.data[index]['answer_end'] = answer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=torch.load(\"../datasets/ms-marco_train_qa.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'answer', 'context', 'answer_start', 'answer_end'],\n",
       "        num_rows: 301763\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'answer', 'context', 'answer_start', 'answer_end'],\n",
       "        num_rows: 201176\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.train_test_split(test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 584861,\n",
       " 'question': 'what causes a rotator cuff tear',\n",
       " 'answer': 'Bleeding and inflammation.',\n",
       " 'context': \"Print. The rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder. A rotator cuff injury can cause a dull ache in the shoulder, which often worsens when you try to sleep on the involved side.he rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder. The rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder.A rotator cuff injury can cause a dull ache in the shoulder, which often worsens when you try to sleep on the involved side.he rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder. In a rotator cuff disorder, tendons that make up the rotator cuff get squeezed and rub against bone. They become damaged and irritated. This causes bleeding and inflammation.The tendons can develop scar tissue, which is not as strong and flexible as normal tendon tissue.n a rotator cuff disorder, tendons that make up the rotator cuff get squeezed and rub against bone. They become damaged and irritated. This causes bleeding and inflammation. Too much stress -- or too many fastballs -- can cause partial tears and swelling in the tendons of the rotator cuff. Abrupt stress may even cause one of the tendons to pull away from the bone or tear in the middle of the tendon.Rotator cuff tears are sometimes incorrectly called ''rotary cuff tears.''.ost rotator cuff tears develop gradually. But they also can happen suddenly -- you might feel a pop, intense pain, and weakness in the arm. To diagnose a rotator cuff tear, your doctor will give you a thorough physical exam. He or she will want you to move your arm in different directions to see what causes pain. The symptoms of a rotator cuff tear include: 1  Pain in the shoulder and arm, which varies depending on how serious the tear is. 2  Weakness and tenderness in the shoulder. 3  Difficulty moving the shoulder, especially when trying to lift your arm above your head. 4  Snapping or crackling sounds when moving the shoulder.ost rotator cuff tears develop gradually. But they also can happen suddenly -- you might feel a pop, intense pain, and weakness in the arm. To diagnose a rotator cuff tear, your doctor will give you a thorough physical exam. He or she will want you to move your arm in different directions to see what causes pain. Rotator Cuff Tears. A rotator cuff tear is a tear of one or more of the tendons of the four rotator cuff muscles. A rotator cuff injury can include any type of irritation or damage to the rotator cuff muscles or tendons.PubMed Health Glossary.he tendons of your rotator cuff can tear for a variety of reasons: 1  An injury, such as falling or being hit in the shoulder. 2  Overuse over time from repeated actions, such as lifting, painting, cleaning windows, or throwing. 3  Natural wear and tear from aging. The rotator cuff is a group of four muscles and tendons that closely surround the shoulder joint. Rotator cuff tears are very common. Most rotator cuff tears are caused by gradual wear of the tendon material as we age.he rotator cuff is a group of four muscles and tendons that closely surround the shoulder joint. Rotator cuff tears are very common. Most rotator cuff tears are caused by gradual wear of the tendon material as we age. 1 Repetitive stress. 2  Repeating the same shoulder motions again and again can stress your rotator cuff muscles and tendons. 3  Baseball, tennis, rowing, and weightlifting are examples of sports activities that can put you at risk for overuse tears. 4  Many jobs and routine chores can cause overuse tears, as well.here is a lubricating sac called a bursa between the rotator cuff and the bone on top of your shoulder (acromion). The bursa allows the rotator cuff tendons to glide freely when you move your arm. When the rotator cuff tendons are injured or damaged, this bursa can also become inflamed and painful. The most common symptoms of a rotator cuff tear include: 1  Pain at rest and at night, particularly if lying on the affected shoulder. 2  Pain when lifting and lowering your arm or with specific movements. 3  Weakness when lifting or rotating your arm. 4  Crepitus or crackling sensation when moving your shoulder in certain positions.here is a lubricating sac called a bursa between the rotator cuff and the bone on top of your shoulder (acromion). The bursa allows the rotator cuff tendons to glide freely when you move your arm. When the rotator cuff tendons are injured or damaged, this bursa can also become inflamed and painful. Re-occurring degeneration and disorganization of the tendons of the rotator cuff can lead to small tears that do not properly heal. This results in a weakened tendon that is more susceptible to serious injuries. The shoulder is a complex joint in the body that is made up of a number of bones, tendons, and muscles.lthough overuse is the most common cause of rotator cuff injuries, other factors are associated with an increased risk of injury, including being male, being older, and having a history of shoulder injury or trauma. The shoulder is subject to other injuries besides rotator cuff tears, including tendinitis and bursitis.\",\n",
       " 'answer_start': 471,\n",
       " 'answer_end': 915}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset['test'].train_test_split(test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid=dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 116924,\n",
       " 'question': 'define  etymological derivation',\n",
       " 'answer': 'The \\u200bstudy of the \\u200borigin and \\u200bhistory of words.',\n",
       " 'context': \"Online Language Dictionaries. English definition English thesaurus English-Spanish English-French English-Italian Spanish-English French-English Italian-English Espanol-Español Francais-Français Francais-Français Espanol-Español Espanol: español Portugues: português Portugues: português espanol... español espanol español definicion definición espanol español sinonimos sinónimos catala català definicio definició more etymology. n, pl-gies. 1. (Linguistics) the study of the sources and development of words and morphemes. 2. (Linguistics) an account of the source and development of a word or morpheme. [C14: via Latin from Greek etumologia; see etymon, -logy]. etymology noun [C or U]. › the \\u200bstudy of the \\u200borigin and \\u200bhistory of words, or a \\u200bstudy of this \\u200btype \\u200brelating to one \\u200bparticular word: At \\u200buniversity she \\u200bdeveloped an \\u200binterest in etymology. A \\u200blist of \\u200bselected words and \\u200btheir etymologies is \\u200bprinted at the back of the \\u200bbook. Noun. 1. etymology-a history of a word. account, chronicle, history, story-a record or narrative description of past events; a history of France; he gave an inaccurate account of the plot to kill the president; the story of exposure to lead. etymology noun [C/U]. › English the \\u200borigin and \\u200bhistory of a word or words, or the \\u200bstudy of word \\u200borigins. (Definition of etymology from the Cambridge Academic Content Dictionary © Cambridge University Press). This is a map of the wheel-ruts of modern English. Etymologies are not definitions; they're explanations of what our words meant and how they sounded 600 or 2,000 years ago. The dates beside a word indicate the earliest year for which there is a surviving written record of that word (in English, unless otherwise indicated). etymology. noun derivation, word history, development of words, history of words, origin of words The etymology of the word 'neon' is the Greek for 'new'. etymology. the branch of linguistics that studies the origin and history of words. — etymologist, n. — etymologie, etymological, adj. the study of the origin and history of individual words. et•y•mo•log•i•cal/ˌɛtəməˈlɑdʒɪkəl/USA pronunciation adj. et•y•mol•o•gist /ˌɛtəˈmɑlədʒɪst/USA pronunciation n. [countable]. 1  Linguistics the history of words or word elements[countable]a dictionary of etymology. 2  Linguistics[uncountable] the study of historical linguistic change in individual words. Collins Concise English Dictionary © HarperCollins Publishers:: etymology /ˌɛtɪˈmɒlədʒɪ/ n (pl-gies) the study of the sources and development of words and morphemes an account of the source and development of a word or morpheme Etymology: 14th Century: via Latin from Greek etumologia; see etymon, -logy.\",\n",
       " 'answer_start': 244,\n",
       " 'answer_end': 525}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test=dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'answer', 'context', 'answer_start', 'answer_end'],\n",
       "    num_rows: 100588\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad=torch.load(\"../datasets/squad.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate max context length for dataset\n",
    "def calc_max_len(dataset):\n",
    "  context_length_max=len(dataset[0]['context'])\n",
    "  for i in range(len(dataset)):\n",
    "    con_len=len(dataset[i]['context'])\n",
    "    if(con_len<context_length_max):\n",
    "      context_length_max=con_len\n",
    "      print(context_length_max)\n",
    "      print(dataset[i]['context'])\n",
    "  return context_length_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5362\n",
      "Relevance. Rating Newest Oldest. Best Answer: SUCROSE is the scientific name of table sugar, is a disaccharide (glucose + fructose) with the molecular formula C12H22O11. Its systematic name is α-D-glucopyranosyl-(1→2)-β-D-fructofuran...It is best known for its role in human nutrition and is formed by plants but not by higher organisms.ts systematic name is α-D-glucopyranosyl-(1→2)-β-D-fructofuran... It is best known for its role in human nutrition and is formed by plants but not by higher organisms. Best Answer: SUCROSE is the scientific name of table sugar, is a disaccharide (glucose + fructose) with the molecular formula C12H22O11.Its systematic name is α-D-glucopyranosyl-(1→2)-β-D-fructofuran... It is best known for its role in human nutrition and is formed by plants but not by higher organisms.ts systematic name is α-D-glucopyranosyl-(1→2)-β-D-fructofuran... It is best known for its role in human nutrition and is formed by plants but not by higher organisms. Answer by Dudeboy3. Confidence votes 28. The name for the simplest sugar that is in our blood is glucose. There are many other kinds as they become more complex. Monosacchrides include glucose and fructose (from fruit), and then there are disacchrides such as table sugar and lactose (milk sugar).ny chemical species dissolved in water has a (water) formula at the end    for example, salt in water is NaCl(water)    The scientific name for solid sugar is C … 12H22O11    The formula for water is H2O    So the formula for sugar water is... While the scientific nomenclature of carbohydrates is complex, the names of the monosaccharides and disaccharides very often end in the suffix-ose. For example, grape sugar is the monosaccharide glucose, cane sugar is the disaccharide sucrose and milk sugar is the disaccharide lactose (see illustration).Carbohydrates perform numerous roles in living organisms.or example, grape sugar is the monosaccharide glucose, cane sugar is the disaccharide sucrose and milk sugar is the disaccharide lactose (see illustration). Carbohydrates perform numerous roles in living organisms.   The scientific name for the sugar glider is Petaurus breviceps     The sugar glider is a small mammal, specifically a marsupial.  Order: Diprodontia   Fami … ly: Petauridae   Genus Species: Petaurus (springboard used by acrobats) breviceps (short).ny chemical species dissolved in water has a (water) formula at the end    for example, salt in water is NaCl(water)    The scientific name for solid sugar is C … 12H22O11    The formula for water is H2O    So the formula for sugar water is... The most common names for sugar are: barley malt, corn syrup, dextrose, fruit juice concentrate, glucose, high-fructose corn syrup, maltodextrin, maltose, molasses, raw sugar, sucrose and turbinado sugar.Here’s a more complete sugar list with 69 sugar names.his list of sugar facts and sugar names will help you uncover the many hidden sugars that are tucked away everywhere in our food today. Biopolymers of sugars are common in nature. Through photosynthesis, plants produce glyceraldehyde-3-phosphate (G3P), a phosphated 3-carbon sugar that is used by the cell to make monosaccharides such as glucose (C 6H 12O 6) or (as in cane and beet) sucrose (C 12H 22O 11).n general, galactose does not occur in the free state but is a constituent with glucose of the disaccharide lactose or milk sugar. It is less sweet than glucose. It is a component of the antigens found on the surface of red blood cells that determine blood groups. A molecule of sucrose. Glucose and fructose are monosaccharide sugars. A monosaccharide is the smallest unit of sugar, mono meaning 1. Sucrose is commonly called table sugar and is a disaccharide. A disaccharide is a sugar that is made up of two sugar units, di meaning 2.Sucrose is produced as glucose and fructose are joined together by a condensation reaction.In the process a water molecule is eliminated. See the following equation.hese sugar molecules include glucose, sucrose, lactose, fructose, maltose, lactose and galactose. Sugar molecules are classified as monosaccharides or disaccharides. The following table lists the common sugar molecules are their chemical formula. Name. (2) Any sweet, crystalline solid disaccharide used as sweetener or preservative. Supplement. The term sugar is the generic term for any disachharides (e.g. sucrose) and monosaccharides (e.g. fructose, glucose). Sugars are essential structural component of living cells and source of energy in many organisms.2) Any sweet, crystalline solid disaccharide used as sweetener or preservative. Supplement. The term sugar is the generic term for any disachharides (e.g. sucrose) and monosaccharides (e.g. fructose, glucose). Sugars are essential structural component of living cells and source of energy in many organisms. The white stuff we know as sugar is sucrose, a molecule composed of 12 atoms of carbon, 22 atoms of hydrogen, and 11 atoms of oxygen (C12H22O11). Like all compounds made from these three elements, sugar is a carbohydrate.Its found naturally in most plants, but especially in sugarcane and sugar beetshence their names.ucrose is actually two simpler sugars stuck together: fructose and glucose. In recipes, a little bit of acid (for example, some lemon juice or cream of tartar) will cause sucrose to break down into these two components.\n",
      "3080\n",
      "Hoda, you are a partner and a friend and a sister, and I am so happy to be doing this. It marks the first time NBC's popular morning show has two female co-anchors. While NBC did not make public just how much Kotb would be earning with this new position — she is still co-hosting Today's fourth hour with Kathie Lee Gifford — many will likely be wondering if she'll be making as much money as Lauer had in that spot. NBC's Today show viewers got a delightful surprise on Tuesday morning, when Savannah Guthrie announced on the show that Hoda Kotb would be the show's new permanent co-host. NBC did not say whether its longtime journalist, whose net worth reportedly stood at $12 million towards the end of 2016, would be getting a raise, but Kotb's salary as a Today anchor might see a substantial increase. Kotb, in comparison, has an estimated net worth of $12 million, according to a 2016 report. Her net worth is only a portion of Lauer's yearly salary. Though she has worked for NBC since 1998, she's yet to become the sort of star whose salary negotiations receive press attention. Kotb was a respected anchor, but she never lorded over Today the way Lauer did. Which might be why her salary in 2018 won't hold a candle to Lauer's pile of cash. Advertisement At the time, Lauer's estimated salary from NBC was between $20-$25 million, making him the highest-paid anchor at the network. His firing from NBC put Megyn Kelly at the top, but it's unclear whether Kotb — or Guthrie, for that matter — will get a pay raise, especially since the Today show's ratings have soared in the wake of Lauer's ousting. An American nationality, Hoda was born in the year 1964 on 9th of August, which makes her 52 years old at this time. She was born in Norman, which lies in Oklahoma in the United States of America to her parents A.K Kotb and Samaha Kotb. Hoda Kotb’s salary for hosting the ‘Today’ show is reportedly much less than what Matt Lauer was making for the same gig. Here’s why she isn’t upset by the huge difference. Hoda Kotb, 53, has officially replaced Matt Lauer, 60, on the Today show — but for a salary that doesn’t even come close to her predecessor‘s. The new host will reportedly make a modest $7 million, according to Page Six. But at the same time, Hoda will also continue to host the 10 a.m. hour of the show with Kathie Lee Gifford, 64, so hopefully she’ll get closer to Matt’s salary considering she’s doing twice the work. Hoda Kotb Husband, Divorce, Boyfriend, Salary and Net Worth. Date: 23 Nov, 2014 Report This. The beautiful and talented Hoda Kotb is one of the most beloved news anchors, and Television shows host in the industry. She has dazzled everyone with her communication skills and demonstrated her marvelous work. Even if the gap between Kotb and Lauer's salary is ignored, what's harder to explain is the fact that $5 million is paltry in comparison to Megyn Kelly's reported $15 million salary. Even Ann Curry, at the time of her departure, made $12 million as Lauer's co-anchor. Kotb may be new to the 7:00 a.m. slot, but she is not new to NBC.\n",
      "2810\n",
      "Copyright 2015 © Howe Insurance Services. *The views, opinions and claims expressed in the videos on this website are intended to share the featured agents personal experiences in working with Howe Insurance Services, Ltd. A top-gun agent once said, Final expense is a simple business, but it ain't easy.. Selling final expense insurance can give you a great opportunity to succeed very well financially. I've known agents making between $200,000 to $300,000 a year. And they only work four or five days a week in the field. The smallest agencies in the revenue range of $500,000 and less had the lowest profit of 4.25 percent, while agencies in the largest revenue range of $3,000,001 and over had the highest profit of 10.00 percent. For comparison purposes, this profit percentage is calculated as a percentage of total revenues. If we look at the best performing “top 25 percent” of agencies for these same revenue ranges, the profit varies from 14.62 percent to 20.11 percent. For example the median expected annual pay for a typical Insurance Agent in the United States is $48,081, so 50% of the people who perform the job of Insurance Agent in the United States are expected to make less than $48,081. Source: HR Reported data as of March 31, 2017. Salary. Salary + Bonus. I've been at the top, AND at the bottom of the final expense business. As an agent selling final expense insurance, I average around $5,000 in new business weekly. I work four days a week, and enjoy the benefits of being a final expense agent. Often people wonder if Selling Final Expense Insurance is a Good Career fit for them. I worked on a salary my entire life but I'm now making more money with Howe Insurance Services than ever before.. Add in the effects of a soft market with reduced agency commissions and revenues, and the need for expense control is even more critical. According to the 2010-2011 Growth and Performance Standards (GPS) study, pre-tax agency profit varies from 4.25 percent to 10.00 percent, depending on agency size. New Final Expense Company Confidential 2. For Agent Training Use Only. ‏ The information contained in this presentation is for agent training. use only and may not be used as a sales tool or as a consumer. marketing piece. Only approved marketing pieces can be used. during a sales presentation. Marketing 101 for the Final Expense Agent. A.Covering the funeral home costs and cemetery fees. B.Not leaving a financial burden for the children. C. Leave a lasting memory, not a funeral/cemetery bill. Primary Purpose for Purchasing. Final Expense Insurance. Marketing 101 for the Final Expense Agent. A. Do NOT use the phone to make appointments. B. Goal is 50 stops per week, average 10 per day, 5 days per week. C. By comparison, a UPS driver in a city makes about 150 stops. per day!\n",
      "2793\n",
      "1 City of Lewisville Health Department Inspections: 2  Public health food safety, violations, retail or wholesale facilities, reports and enforcement. 3  Lewisville Crime Maps: 4  Mapping of Lewisville street locations of criminal reported activity from local law enforcement agencies. Account for ALL PERIODS OF UNEMPLOYMENT. 5. Application must be submitted to the Human Resources Department on or before the closing date of the position, or mailed to the City of Lewisville Human Resources Department, P.O. Box 299002, Lewisville, TX 75029-9002. Applications submitted or postmarked after the closing date will not be considered. Rawlins, Kealy, and Herod built a gristmill in Lewisville in 1862. Several stores were built, and by 1867 T. M. Clayton and George Craft built the first cotton gin in Denton County there. In 1868–69 the first church was built at Lewisville, and the first Masonic lodge of the county was housed there. Lewisville grew rapidly after the arrival of the Dallas and Wichita Railway in 1881. Request criminal records specific to the City of Lewisville, from law enforcement departments with access to the state's repository with official background check of arrests and convicted felonies. Access a directory aimed toward producing open public records and instant information available online. Lewisville /ˈljuː.ɪs.vɪl/ is a city in Denton County, Texas, United States. In The Spotlight. The annual Spooktacular Trails and Glow Run will be held on Saturday, October 24. This family fun event includes a digital costume contest, hayride, trick-or-treating, entertainment, activities, and the Glow Run 5k and Monster Mile. 1  Latest News. 2  Upcoming Events. 1 City of Lewisville Court Records: 2  Criminal cases, civil filings, divorces, bankruptcy and judgments. 3  City of Lewisville Official Website: 4  Government department official public web-portal. 5  City of Lewisville Municipal Codes: 6  City ordinances governing cities, villages, parishes and jurisdictions below state level. LEWISVILLE, TEXAS (Denton County). Lewisville is nine miles northeast of the Dallas-Fort Worth International Airport qv in southeastern Denton County, ringed by Dallas, Fort Worth, and Denton. The site was part of the Peters colony. Mission: To ensure that your tax dollars are accurately and efficiently collected with the utmost integrity and honesty. Goal: To exceed your expectations by ensuring the highest level of service possible using technology, tools and services to assist our taxpayers in transacting business with our office. Look up recorded information of Lewisville, including demographics and local economy. Link to all levels of Lewisville, government and their sites with services which provide public information. Current economy, business and housing data.\n",
      "2452\n",
      "A rattling cough is a condition which causes a rustling, rattling, or wheezing sound in the chest or throat accompanied by a chronic cough. The troublesome noises are generally caused by mucus accumulation in the chest or by sinus drainage into the throat. The common cold may cause rattling cough symptoms. A rattling cough should be checked out by a doctor, particularly if it occurs in young children. Most rattling coughs are remnants of a congestive illness such as bronchitis. A rattling cough is accompanied by troublesome chest or throat sounds. A rattling cough is accompanied by troublesome chest or throat sounds. A rattling cough may be caused by chest congestion. A dry cough might be treated using a humidifier. A rattling cough may be accompanied by laboring breathing, depending on the type of infection. Occasionally, a rattling cough can signal a serious health condition. Pneumonia, an infection of the lungs, is a condition which often occurs as the result of a less threatening illness which fails to heal, such as influenza. Large amounts of mucus may form and block airways. Occasionally, a rattling cough can signal a serious health condition. Pneumonia, an infection of the lungs, is a condition which often occurs as the result of a less threatening illness which fails to heal, such as influenza. Phlegm, a tight feeling and a rattle when you inhale – these are all symptoms of a chesty cough. Also known as a wet cough or a productive cough, it’s the result of having too much thick phlegm in your airways. This sticky liquid can be white, yellow or green and comes up during coughing. Bronchitis occurs when the air passages in your lungs become inflamed. Bronchitis can be acute or chronic. Acute bronchitis is usually due to a viral infection, such as a cold, that starts in your nose or sinuses and spreads to the airways. Phlegm, a tight feeling and a rattle when you inhale – these are all symptoms of a chesty cough. Also known as a wet cough or a productive cough, it’s the result of having too much thick phlegm in your airways. Bronchitis can be acute or chronic. Acute bronchitis is usually due to a viral infection, such as a cold, that starts in your nose or sinuses and spreads to the airways. Acute bronchitis usually lasts a few days, but you may have a cough for weeks afterward. Dr. Bob explains the different causes of a dry cough and a rattling cough. For more health information visit www.drbobshow.com.\n",
      "2360\n",
      "Definition of cover for English Language Learners : to put something over, on top of, or in front of (something else) especially in order to protect, hide, or close it : to be spread over or on top of (something) Definition of cover for English Language Learners. : 1  to put something over, on top of, or in front of (something else) especially in order to protect, hide, or close it. : 2  to be spread over or on top of (something) : 3  to be over much or all of the surface of (something) To cover something with or in something else means to put a layer of the second thing over its surface. The trees in your garden may have covered the ground with apples, pears or plums. [V n + with/in] She covered the walls with the signs of the zodiac. [V n with/in n] legal Definition of cover : purchase of goods in substitution for those originally contracted for when the seller fails to fulfill the contract the buyer is always free to choose between cover and damages for nondelivery Definition of cover for Students. 1  1 : something that protects, shelters, or hides. 2  2 : a covering (as a blanket) used on a bed. 3  3 : a binding or a protecting case a book cover. 4  4 : something that is placed over or about another thing : lid, top a mattress cover the cover of a box. Examples of cover in a Sentence. 1  She placed a cover over the pan so that the oil wouldn't spatter. 2  I put a cover on the sofa to protect it. 3  There's a picture of the author on the book's back cover. 4  The singer is posing in jeans and cowboy boots on the album cover. Definition of cover for English Language Learners : something that is put around or on top of another thing especially to protect, hide, or close it : a blanket or sheet on a bed To cover something with or in something else means to put a layer of the second thing over its surface. The trees in your garden may have covered the ground with apples, pears or plums. If you cover a particular distance, you travel that distance. It would not be easy to cover ten miles on that amount of petrol. Define cover: to guard from attack; to have within the range of one's guns : command; to hold within range of an aimed firearm — cover in a sentence She placed a cover over the pan so that the oil wouldn't spatter. I put a cover on the sofa to protect it. There's a picture of the author on the book's back cover.\n",
      "2313\n",
      "1. a story or account of events, experiences, or the like, whether true or fictitious. 2. the art, technique, or process of narrating. 3. consisting of or being a narrative: narrative poetry. The most thoroughgoing of all distinctions in literature, as in the other Fine Arts, is that between (1) Substance, the essential content and meaning of the work, and (2) Form, the manner in which it is expressed (including narrative structure, external style, in poetry verse-form, and many related matters). When you write a narrative essay, you are telling a story. Narrative essays are told from a defined point of view, often the author's, so there is feeling as well as specific and often sensory details provided to get the reader involved in the elements and sequence of the story. One last component of narrative writing is point of view. Point of view is the perspective in which the story is told. The two main points of view are first-person and third-person. Setting. The setting is another component of narrative writing. The setting is the time and the location in which the story takes place. These facts set the scene for the story and can determine what kind of conflict occurs. In this lesson you will learn what makes a piece of writing a narrative. Examples are also given to illustrate the specific types of narrative writing, and the lesson will be followed by a quiz. 1 narratage-The technique of having one character in the role of storyteller or the act of inserting bits of explanation into a narrative. 2  narrative-First an adjective meaning telling the facts of a story, from Latin narrare, which is also the base of narrate. 1 narrative-First an adjective meaning telling the facts of a story, from Latin narrare, which is also the base of narrate. narrative. 1  narratage-The technique of having one character in the role of storyteller or the act of inserting bits of explanation into a narrative. 2  narrative-First an adjective meaning telling the facts of a story, from Latin narrare, which is also the base of narrate. There are many types of narrative writing. Basically any written work that tells a story can be labeled as narrative writing. Here's a list of some of the most common types, with examples. 1  Novels-usually more lengthy and can be divided into chapters or sections.\n",
      "1574\n",
      "Topix › Kentucky › Casey County › Yosemite › Yosemite Forum. Join the discussion! This forum covers Yosemite, KY local community news, events for your calendar, and updates from colleges, churches, sports, and classifieds. Canadian Postal Code Database. Get all Canadian Postal Codes and their information in one easy to use database. 2010 Census Database. Get the 2010 Census data in an easy to use format for all summary levels: National, State, COunty, City, and Congressional District. Yosemite, KY. Yosemite is located close to the center of Kentucky. Yosemite is part of Casey County. On average, the public school district that covers Yosemite is better than the state average in quality. The Yosemite area code is 606. Local news for Yosemite, KY continually updated from thousands of sources on the web. Yosemite, Kentucky is located in Casey County. Zip codes in Yosemite, KY include 42566. The median home price in Yosemite is $2 which is roughly $2/per square foot. Covering every address in the U.S., get the +4 information you need. Get all Canadian Postal Codes and their information in one easy to use database. Get the 2010 Census data in an easy to use format for all summary levels: National, State, COunty, City, and Congressional District. Get all Area Codes and NXX data for North America. Yosemite, Kentucky. Yosemite is an unincorporated community in eastern Casey County, Kentucky, United States. Their Post Office was closed in September 2011. It was established in the 1870s for logging facilities owned by Cincinnati businessman Eugene Zimmerman.\n",
      "1275\n",
      "Life Care Center of Carrollton is a part of Life Care Centers of America that operates more than 200 skilled-nursing homes, assisted-living facilities, retirement living communities, home care services and Alzheimer's centers. Hours. Life Care Center of Carrollton is a provider of nursing home and long-term health care services to residents of the northern Worcester County. Life Care Center of Carrollton is a part of Life Care Centers of America that operates more than 200 skilled-nursing homes, assisted-living facilities, retirement living communities, home care services and Alzheimer's centers. Quick Links. Welcome to Life Care Center of Carrollton. In the rural town of Carrollton, Missouri, Life Care Center of Carrollton has easy access to many state parks and conservation areas. Located in Carrollton, Mo., the center offers a suite of services, including in-home nursing care, therapy, experienced sitters, extended live-in arrangements, Alzheimer's care, rehabilitation or recovery and other assisted living services. Located in Carrollton, Mo., the center offers a suite of services, including in-home nursing care, therapy, experienced sitters, extended live-in arrangements, Alzheimer's care, rehabilitation or recovery and other assisted living services.\n",
      "1042\n",
      "For population 25 years and over in Macksville: 1  High school or higher: 77.9%. 2  Bachelor's degree or higher: 16.9%. 3  Graduate or professional degree: 5.2 4 %. Unemployed: 1. 5 4%. Mean travel time to work (commute): 16.2 minutes. Central Standard Time - is abbreviated as CST. Central Daylight Time- is abbreviated as CDT. Marysville, Kansas is GMT/UTC - 6h during Standard Time. Marysville, Kansas is GMT/UTC - 5h during Daylight Saving Time. Macksville, Kansas. Macksville is a city in Stafford County, Kansas, United States. As of the 2010 census, the city population was 549. Latest news from Macksville, KS collected exclusively by city-data.com from local newspapers, TV, and radio stations. Ancestries: German (12.7%), American (8.3%), English (5.1%), European (2.9%), Irish (1.1%). Current Local Time: CST time zone. Elevation: 2035 feet. Area code 620 was put into service when (620) 914- was introduced as the first prefix. Major Cities in Area Code 620. 1  Dodge City, KS. 2  Emporia, KS. 3  Garden City, KS.  Hutchinson, KS.\n",
      "858\n",
      "this article: Kiiara is a 20-year-old from Illinois whose new single “Gold” feels like some fascinating new mutation of bedroom-pop music. “Gold,” a collaboration with producer Felix Snow, takes cues from icy R&B and from glitched-out, spacey dance music, but it also has the wide-open heart of a classic pop song.Gold,” a collaboration with producer Felix Snow, takes cues from icy R&B and from glitched-out, spacey dance music, but it also has the wide-open heart of a classic pop song. iTunes is the world's easiest way to organize and add to your digital media collection. We are unable to find iTunes on your computer. To download from the iTunes Store, get iTunes now.Tunes is the world's easiest way to organize and add to your digital media collection. We are unable to find iTunes on your computer. To download from the iTunes Store, get iTunes now.\n",
      "301\n",
      "Clue: Before noon it's one and the same. We have 1 possible answer for the clue Before noon it's one and the same which appears 1 time in our database.lue: Before noon it's one and the same. We have 1 possible answer for the clue Before noon it's one and the same which appears 1 time in our database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_max_len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# sep_token = '<sep>'\n",
    "dataset_name = \"ms_marco\"\n",
    "model_type=\"roberta\"\n",
    "model_name= \"roberta-base\"\n",
    "models_dir = \"saved_models/roberta-base_ms-marco_mod\"\n",
    "checkpoint = 'roberta-base'\n",
    "max_input_length = 301\n",
    "\n",
    "\n",
    "# ## Training\n",
    "learning_rate = 3e-5\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_input_length ,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answer\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = examples[\"answer_start\"]\n",
    "        print(len(start_char))\n",
    "        \n",
    "        end_char = examples[\"answer_end\"]\n",
    "        print(len(end_char))\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        print(offset[context_start][0])\n",
    "        print(end_char)\n",
    "        print(offset[context_end][1])\n",
    "        print(start_char)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform your custom dataset to a PyTorch dataset\n",
    "# dataset = datasets.Dataset.from_generator(\n",
    "#     generator=lambda: iter(dataset)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to C:/Users/dama_/.cache/huggingface/datasets/generator/default-1f482045682b315d/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to C:/Users/dama_/.cache/huggingface/datasets/generator/default-1f482045682b315d/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# dataset_val= datasets.Dataset.from_generator(\n",
    "#     generator=lambda: iter(dataset_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset,\"../datasets/ms-marco_train_qa.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset_valid,\"../datasets/ms-marco_valid_qa.pt\")# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'answer', 'context', 'answer_start', 'answer_end'],\n",
       "    num_rows: 301763\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 584861,\n",
       " 'question': 'what causes a rotator cuff tear',\n",
       " 'answer': 'Bleeding and inflammation.',\n",
       " 'context': \"Print. The rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder. A rotator cuff injury can cause a dull ache in the shoulder, which often worsens when you try to sleep on the involved side.he rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder. The rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder.A rotator cuff injury can cause a dull ache in the shoulder, which often worsens when you try to sleep on the involved side.he rotator cuff is a group of muscles and tendons that surround the shoulder joint, keeping the head of your upper arm bone firmly within the shallow socket of the shoulder. In a rotator cuff disorder, tendons that make up the rotator cuff get squeezed and rub against bone. They become damaged and irritated. This causes bleeding and inflammation.The tendons can develop scar tissue, which is not as strong and flexible as normal tendon tissue.n a rotator cuff disorder, tendons that make up the rotator cuff get squeezed and rub against bone. They become damaged and irritated. This causes bleeding and inflammation. Too much stress -- or too many fastballs -- can cause partial tears and swelling in the tendons of the rotator cuff. Abrupt stress may even cause one of the tendons to pull away from the bone or tear in the middle of the tendon.Rotator cuff tears are sometimes incorrectly called ''rotary cuff tears.''.ost rotator cuff tears develop gradually. But they also can happen suddenly -- you might feel a pop, intense pain, and weakness in the arm. To diagnose a rotator cuff tear, your doctor will give you a thorough physical exam. He or she will want you to move your arm in different directions to see what causes pain. The symptoms of a rotator cuff tear include: 1  Pain in the shoulder and arm, which varies depending on how serious the tear is. 2  Weakness and tenderness in the shoulder. 3  Difficulty moving the shoulder, especially when trying to lift your arm above your head. 4  Snapping or crackling sounds when moving the shoulder.ost rotator cuff tears develop gradually. But they also can happen suddenly -- you might feel a pop, intense pain, and weakness in the arm. To diagnose a rotator cuff tear, your doctor will give you a thorough physical exam. He or she will want you to move your arm in different directions to see what causes pain. Rotator Cuff Tears. A rotator cuff tear is a tear of one or more of the tendons of the four rotator cuff muscles. A rotator cuff injury can include any type of irritation or damage to the rotator cuff muscles or tendons.PubMed Health Glossary.he tendons of your rotator cuff can tear for a variety of reasons: 1  An injury, such as falling or being hit in the shoulder. 2  Overuse over time from repeated actions, such as lifting, painting, cleaning windows, or throwing. 3  Natural wear and tear from aging. The rotator cuff is a group of four muscles and tendons that closely surround the shoulder joint. Rotator cuff tears are very common. Most rotator cuff tears are caused by gradual wear of the tendon material as we age.he rotator cuff is a group of four muscles and tendons that closely surround the shoulder joint. Rotator cuff tears are very common. Most rotator cuff tears are caused by gradual wear of the tendon material as we age. 1 Repetitive stress. 2  Repeating the same shoulder motions again and again can stress your rotator cuff muscles and tendons. 3  Baseball, tennis, rowing, and weightlifting are examples of sports activities that can put you at risk for overuse tears. 4  Many jobs and routine chores can cause overuse tears, as well.here is a lubricating sac called a bursa between the rotator cuff and the bone on top of your shoulder (acromion). The bursa allows the rotator cuff tendons to glide freely when you move your arm. When the rotator cuff tendons are injured or damaged, this bursa can also become inflamed and painful. The most common symptoms of a rotator cuff tear include: 1  Pain at rest and at night, particularly if lying on the affected shoulder. 2  Pain when lifting and lowering your arm or with specific movements. 3  Weakness when lifting or rotating your arm. 4  Crepitus or crackling sensation when moving your shoulder in certain positions.here is a lubricating sac called a bursa between the rotator cuff and the bone on top of your shoulder (acromion). The bursa allows the rotator cuff tendons to glide freely when you move your arm. When the rotator cuff tendons are injured or damaged, this bursa can also become inflamed and painful. Re-occurring degeneration and disorganization of the tendons of the rotator cuff can lead to small tears that do not properly heal. This results in a weakened tendon that is more susceptible to serious injuries. The shoulder is a complex joint in the body that is made up of a number of bones, tendons, and muscles.lthough overuse is the most common cause of rotator cuff injuries, other factors are associated with an increased risk of injury, including being male, being older, and having a history of shoulder injury or trauma. The shoulder is subject to other injuries besides rotator cuff tears, including tendinitis and bursitis.\",\n",
       " 'answer_start': 471,\n",
       " 'answer_end': 915}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "0\n",
      "[915, 1116, 806, 523, 1064, 376, 256, 1287, 686, 212, 613, 157, 594, 950, 264, 541, 708, 191, 569, 1109, 641, 904, 658, 1368, 265, 645, 601, 1133, 614, 485, 626, 587, 599, 756, 343, 1096, 643, 472, 542, 424, 466, 538, 598, 1213, 487, 612, 356, 1178, 180, 560, 569, 272, 1196, 589, 249, 522, 986, 347, 500, 913, 733, 791, 631, 587, 602, 937, 270, 711, 397, 691, 299, 854, 635, 495, 517, 377, 537, 512, 603, 1106, 375, 450, 483, 525, 616, 589, 631, 445, 491, 451, 561, 611, 1055, 634, 425, 500, 1172, 998, 509, 644, 1112, 741, 569, 1144, 579, 678, 600, 1081, 484, 805, 744, 476, 659, 504, 294, 371, 776, 792, 1048, 937, 1006, 457, 557, 427, 1145, 693, 904, 552, 521, 350, 1130, 907, 1123, 241, 132, 677, 345, 504, 684, 684, 301, 540, 605, 1010, 260, 1041, 961, 487, 518, 393, 611, 410, 655, 569, 358, 1032, 630, 647, 1286, 1166, 283, 676, 256, 262, 618, 867, 500, 900, 960, 596, 234, 1129, 1118, 510, 264, 592, 310, 308, 690, 251, 296, 297, 575, 900, 522, 562, 559, 1081, 632, 536, 898, 733, 491, 336, 731, 512, 718, 582, 693, 434, 567, 558, 718, 358, 530, 584, 526, 765, 603, 775, 321, 583, 538, 531, 503, 601, 443, 573, 605, 514, 637, 577, 587, 623, 238, 560, 778, 504, 637, 613, 332, 550, 752, 596, 642, 423, 491, 889, 528, 650, 592, 767, 914, 449, 668, 640, 539, 509, 243, 768, 633, 574, 496, 397, 485, 641, 467, 443, 536, 375, 603, 533, 597, 497, 401, 486, 590, 631, 276, 533, 674, 222, 469, 422, 473, 564, 575, 442, 565, 669, 303, 654, 789, 607, 572, 244, 594, 668, 429, 587, 417, 313, 603, 1042, 645, 335, 315, 542, 551, 1084, 587, 416, 614, 503, 561, 1221, 474, 596, 688, 1094, 1154, 438, 492, 446, 548, 758, 494, 1029, 718, 579, 350, 730, 557, 500, 501, 727, 634, 978, 940, 514, 1182, 633, 505, 516, 561, 380, 683, 614, 569, 655, 510, 793, 594, 678, 734, 1092, 337, 1296, 488, 212, 307, 372, 573, 589, 538, 676, 520, 264, 609, 457, 390, 739, 1124, 630, 1516, 617, 529, 833, 604, 760, 552, 317, 838, 1242, 601, 509, 734, 627, 319, 330, 589, 551, 516, 1602, 721, 560, 778, 324, 720, 629, 447, 621, 542, 557, 455, 544, 453, 626, 898, 555, 561, 561, 531, 632, 595, 449, 713, 1233, 371, 974, 660, 378, 1014, 293, 553, 626, 1089, 586, 312, 481, 474, 538, 1406, 314, 615, 534, 752, 619, 615, 320, 301, 1367, 374, 637, 509, 722, 985, 689, 747, 653, 232, 260, 912, 490, 690, 442, 397, 511, 617, 1084, 562, 682, 743, 236, 819, 548, 704, 496, 372, 463, 973, 617, 276, 1008, 662, 226, 582, 776, 318, 610, 701, 236, 595, 431, 514, 545, 693, 473, 473, 225, 878, 700, 485, 778, 603, 562, 623, 321, 219, 298, 783, 603, 680, 639, 535, 642, 401, 231, 599, 1010, 255, 639, 306, 1164, 540, 554, 445, 806, 732, 583, 256, 453, 893, 992, 598, 301, 509, 478, 603, 543, 508, 586, 421, 286, 714, 600, 642, 604, 583, 443, 533, 681, 559, 602, 601, 480, 854, 687, 580, 1198, 436, 1070, 460, 475, 585, 1074, 470, 530, 582, 1101, 975, 926, 803, 680, 870, 712, 1131, 491, 357, 741, 288, 493, 585, 682, 473, 759, 1270, 546, 940, 529, 610, 436, 437, 608, 471, 666, 1134, 618, 525, 704, 695, 326, 523, 1010, 832, 465, 428, 502, 437, 747, 567, 500, 529, 1105, 751, 669, 428, 397, 481, 593, 261, 518, 605, 529, 461, 750, 695, 370, 527, 316, 611, 959, 1252, 318, 611, 485, 742, 518, 589, 779, 610, 661, 967, 515, 934, 1206, 405, 600, 577, 814, 545, 793, 950, 288, 603, 536, 887, 266, 669, 901, 666, 534, 307, 545, 548, 547, 715, 710, 650, 569, 401, 565, 712, 983, 623, 1076, 536, 670, 739, 404, 292, 794, 217, 773, 1392, 575, 702, 519, 706, 737, 701, 945, 500, 346, 532, 492, 719, 287, 566, 747, 609, 1568, 231, 754, 256, 464, 326, 353, 663, 685, 631, 215, 627, 555, 589, 484, 523, 564, 548, 676, 544, 493, 814, 1150, 654, 809, 508, 632, 565, 1067, 511, 724, 401, 208, 623, 498, 903, 809, 693, 561, 491, 731, 614, 444, 564, 187, 219, 208, 435, 963, 465, 595, 387, 542, 499, 287, 862, 158, 785, 571, 941, 1282, 540, 247, 647, 361, 275, 556, 536, 797, 312, 764, 1060, 451, 263, 1120, 241, 827, 539, 546, 581, 1033, 255, 312, 675, 758, 645, 860, 439, 636, 276, 428, 847, 451, 362, 711, 964, 332, 732, 735, 552, 376, 585, 574, 543, 493, 292, 569, 613, 477, 549, 832, 571, 612, 811, 1049, 302, 528, 818, 525, 742, 576, 271, 463, 493, 1003, 475, 936, 509, 603, 586, 155, 832, 443, 703, 552, 628, 489, 583, 584, 381, 312, 1067, 830, 463, 885, 340, 744, 663, 1221, 578, 595, 580, 541, 562, 228, 709, 762, 443, 551, 557, 279, 528, 880, 315, 528, 573, 651, 824, 238, 710, 967, 635, 596, 474, 256, 172, 668, 471, 468, 515, 631, 684, 587, 553, 626, 1260, 335, 567, 551, 411, 247, 1179, 572, 628, 271, 625, 229, 385, 616, 536, 639, 647, 1248, 685, 524, 863, 766, 675, 542, 700, 217, 403, 678, 664, 600, 472, 877, 608, 777, 579, 933, 723, 532, 341, 909, 515, 561, 500, 255, 603, 507, 550, 516, 545, 607, 762, 496, 644, 1048, 594, 768, 604, 528, 459, 603, 458, 567, 333, 1460, 217, 790, 297, 1258, 753, 910, 945, 610, 1101, 210, 551, 981, 601, 279, 571, 646, 978, 531, 526, 522, 629, 864, 304, 499, 662, 817, 581, 613, 529, 218, 519, 834, 571, 520, 633, 589, 335, 419, 1093, 617, 469, 630, 379, 554, 751, 1259, 513, 961, 419, 527, 650, 424, 251, 568, 304, 317, 586, 443, 711, 960, 1254, 454, 628, 1060, 558, 1081, 606, 245, 616, 434]\n",
      "1396\n",
      "[471, 540, 416, 222, 536, 301, 0, 526, 385, 0, 298, 0, 226, 485, 0, 339, 274, 0, 320, 496, 195, 281, 313, 820, 0, 0, 312, 651, 309, 223, 310, 257, 305, 330, 0, 627, 330, 279, 305, 176, 251, 283, 333, 624, 290, 411, 0, 654, 0, 300, 263, 0, 651, 210, 85, 211, 397, 0, 295, 484, 221, 332, 321, 310, 256, 474, 0, 298, 202, 262, 0, 409, 373, 195, 233, 208, 239, 183, 318, 561, 0, 0, 0, 213, 0, 348, 261, 299, 284, 199, 255, 344, 492, 0, 0, 0, 627, 341, 208, 357, 557, 434, 337, 721, 264, 318, 283, 595, 246, 281, 477, 211, 344, 203, 0, 309, 506, 491, 579, 426, 533, 0, 266, 184, 559, 296, 514, 281, 278, 0, 817, 457, 610, 0, 0, 348, 275, 252, 394, 270, 0, 0, 295, 304, 0, 437, 548, 204, 287, 0, 318, 89, 283, 312, 106, 490, 313, 286, 736, 574, 164, 367, 0, 0, 283, 201, 317, 312, 721, 379, 0, 558, 679, 304, 0, 293, 0, 0, 300, 192, 0, 0, 324, 383, 303, 303, 0, 513, 315, 0, 536, 381, 274, 0, 372, 0, 299, 248, 323, 171, 266, 300, 235, 0, 309, 246, 266, 278, 271, 263, 0, 278, 238, 315, 179, 347, 237, 0, 266, 301, 317, 282, 288, 0, 0, 254, 306, 159, 286, 341, 194, 253, 353, 260, 0, 226, 364, 468, 287, 382, 469, 194, 0, 302, 351, 0, 312, 273, 0, 367, 308, 298, 0, 0, 217, 293, 250, 213, 307, 233, 302, 250, 279, 249, 0, 146, 0, 317, 0, 283, 306, 0, 0, 148, 280, 297, 211, 72, 279, 333, 0, 209, 307, 317, 317, 0, 345, 335, 168, 298, 0, 0, 306, 420, 175, 0, 0, 0, 233, 535, 240, 106, 240, 309, 277, 653, 263, 343, 356, 605, 585, 204, 247, 239, 318, 468, 269, 566, 212, 302, 209, 0, 242, 274, 244, 342, 319, 489, 659, 0, 567, 308, 234, 0, 227, 188, 311, 0, 166, 341, 271, 0, 292, 227, 334, 485, 0, 681, 281, 0, 0, 171, 319, 305, 277, 317, 282, 0, 302, 303, 0, 284, 561, 316, 933, 289, 313, 362, 251, 445, 309, 0, 287, 667, 250, 200, 410, 284, 0, 0, 289, 0, 264, 747, 401, 252, 442, 182, 437, 297, 102, 320, 253, 258, 0, 278, 0, 303, 531, 332, 290, 250, 281, 300, 293, 283, 253, 436, 0, 284, 261, 0, 514, 0, 213, 308, 591, 0, 158, 200, 263, 222, 636, 0, 307, 231, 323, 321, 331, 0, 0, 742, 91, 0, 0, 455, 543, 347, 386, 212, 0, 0, 486, 298, 389, 311, 179, 267, 297, 641, 344, 305, 499, 0, 471, 154, 243, 181, 212, 311, 345, 307, 0, 306, 351, 0, 314, 534, 0, 302, 397, 0, 360, 0, 266, 273, 371, 242, 165, 0, 299, 369, 201, 264, 319, 306, 361, 0, 0, 0, 515, 308, 300, 269, 290, 305, 240, 0, 282, 530, 0, 0, 0, 561, 230, 311, 0, 551, 327, 325, 0, 201, 589, 509, 280, 0, 0, 147, 338, 274, 227, 266, 0, 0, 314, 314, 221, 250, 274, 227, 246, 361, 309, 322, 327, 0, 548, 256, 312, 557, 0, 625, 231, 249, 321, 621, 0, 258, 281, 516, 458, 463, 404, 324, 305, 395, 575, 250, 229, 0, 0, 237, 282, 350, 252, 316, 652, 300, 410, 269, 264, 246, 200, 337, 168, 301, 590, 308, 0, 311, 460, 171, 227, 620, 571, 263, 0, 316, 272, 209, 313, 294, 298, 621, 0, 236, 0, 0, 259, 322, 0, 252, 0, 172, 280, 490, 242, 0, 320, 0, 330, 289, 672, 0, 314, 295, 460, 285, 0, 274, 295, 246, 311, 277, 365, 721, 0, 296, 387, 0, 342, 0, 481, 0, 344, 389, 463, 0, 321, 467, 171, 291, 0, 273, 246, 251, 296, 421, 332, 274, 220, 296, 333, 532, 302, 532, 293, 319, 574, 0, 0, 395, 0, 426, 789, 308, 360, 320, 0, 299, 521, 455, 193, 0, 258, 256, 312, 193, 295, 457, 280, 811, 0, 300, 0, 275, 0, 232, 0, 302, 266, 0, 424, 248, 286, 218, 299, 313, 280, 302, 243, 248, 334, 536, 309, 318, 285, 304, 268, 313, 283, 316, 154, 0, 379, 0, 567, 478, 0, 214, 307, 435, 287, 249, 269, 0, 0, 0, 316, 337, 0, 288, 165, 302, 0, 0, 0, 0, 346, 287, 628, 497, 249, 0, 305, 288, 0, 305, 220, 464, 0, 447, 467, 84, 0, 609, 0, 457, 218, 209, 277, 548, 0, 0, 378, 293, 237, 404, 110, 320, 0, 0, 476, 198, 224, 300, 505, 200, 354, 262, 256, 0, 351, 257, 301, 299, 0, 253, 351, 272, 262, 212, 287, 378, 345, 458, 0, 300, 560, 290, 469, 0, 0, 286, 224, 519, 249, 483, 321, 276, 265, 0, 0, 284, 281, 286, 281, 271, 297, 282, 0, 0, 593, 486, 0, 491, 222, 295, 285, 787, 372, 317, 297, 268, 289, 65, 290, 472, 200, 253, 229, 117, 227, 521, 0, 222, 253, 225, 273, 0, 309, 317, 347, 294, 202, 0, 0, 310, 234, 255, 205, 203, 436, 303, 317, 312, 834, 0, 286, 314, 186, 0, 607, 229, 343, 110, 332, 0, 169, 284, 301, 387, 245, 704, 275, 269, 345, 291, 321, 236, 372, 0, 0, 329, 363, 0, 0, 439, 317, 512, 265, 495, 230, 299, 0, 366, 0, 304, 0, 0, 309, 300, 273, 262, 289, 262, 317, 207, 383, 509, 215, 279, 275, 233, 271, 255, 324, 349, 216, 643, 87, 325, 0, 654, 401, 391, 461, 0, 240, 0, 244, 515, 243, 0, 0, 286, 480, 256, 0, 0, 314, 458, 0, 247, 0, 319, 297, 318, 217, 0, 215, 295, 249, 246, 313, 306, 0, 0, 556, 306, 204, 288, 194, 271, 258, 782, 232, 452, 268, 255, 253, 304, 0, 0, 0, 0, 250, 340, 313, 469, 505, 255, 0, 440, 299, 566, 287, 0, 312, 179]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_msmarco_train \u001b[39m=\u001b[39m dataset_train\u001b[39m.\u001b[39;49mmap(preprocess_function, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, remove_columns\u001b[39m=\u001b[39;49mdataset_train\u001b[39m.\u001b[39;49mcolumn_names)\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    526\u001b[0m }\n\u001b[0;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3004\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2996\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2997\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   2998\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   2999\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3002\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3003\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3004\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3005\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   3006\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3380\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3376\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   3377\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[0;32m   3378\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3380\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[0;32m   3381\u001b[0m         batch,\n\u001b[0;32m   3382\u001b[0m         indices,\n\u001b[0;32m   3383\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m   3384\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m   3385\u001b[0m     )\n\u001b[0;32m   3386\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3387\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3389\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3261\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3259\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   3260\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 3261\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[0;32m   3262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3263\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[0;32m   3264\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[0;32m   3265\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[45], line 40\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mprint\u001b[39m(offset[context_end][\u001b[39m1\u001b[39m])\n\u001b[0;32m     39\u001b[0m \u001b[39mprint\u001b[39m(start_char)\n\u001b[1;32m---> 40\u001b[0m \u001b[39mif\u001b[39;00m offset[context_start][\u001b[39m0\u001b[39;49m] \u001b[39m>\u001b[39;49m end_char \u001b[39mor\u001b[39;00m offset[context_end][\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m start_char:\n\u001b[0;32m     41\u001b[0m     start_positions\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n\u001b[0;32m     42\u001b[0m     end_positions\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "tokenized_msmarco_train = dataset_train.map(preprocess_function, batched=True, remove_columns=dataset_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "tokenized_msmarco_val=dataset_valid.map(preprocess_function, batched=True, remove_columns=dataset_valid.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\HOGENT\\2022_2023\\BA\\BP_Info_Support\\bert\\saved_models/roberta-base_ms-marco_mod is already a clone of https://huggingface.co/damapika/roberta-base_ms-marco_mod. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=models_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_msmarco_train,\n",
    "    eval_dataset=tokenized_msmarco_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (9173) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [16, 9173].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1638\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1902\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1905\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1906\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1907\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1908\u001b[0m ):\n\u001b[0;32m   1909\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2642\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2644\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2645\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2647\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2648\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2677\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2675\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2676\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2677\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[0;32m   2678\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1516\u001b[0m, in \u001b[0;36mRobertaForQuestionAnswering.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[39mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[39m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[39m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1516\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[0;32m   1517\u001b[0m     input_ids,\n\u001b[0;32m   1518\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1519\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1520\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1521\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1522\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1523\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1524\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1525\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1526\u001b[0m )\n\u001b[0;32m   1528\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1530\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqa_outputs(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\dama_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:818\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings, \u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    817\u001b[0m     buffered_token_type_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 818\u001b[0m     buffered_token_type_ids_expanded \u001b[39m=\u001b[39m buffered_token_type_ids\u001b[39m.\u001b[39;49mexpand(batch_size, seq_length)\n\u001b[0;32m    819\u001b[0m     token_type_ids \u001b[39m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (9173) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [16, 9173].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
